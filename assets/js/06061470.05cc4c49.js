"use strict";(self.webpackChunksleepy_discord_docs=self.webpackChunksleepy_discord_docs||[]).push([[8947],{3905:function(e,n,t){t.d(n,{Zo:function(){return l},kt:function(){return m}});var i=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,i,r=function(e,n){if(null==e)return{};var t,i,r={},o=Object.keys(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var c=i.createContext({}),d=function(e){var n=i.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},l=function(e){var n=d(e.components);return i.createElement(c.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},p=i.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),p=d(t),m=r,g=p["".concat(c,".").concat(m)]||p[m]||u[m]||o;return t?i.createElement(g,a(a({ref:n},l),{},{components:t})):i.createElement(g,a({ref:n},l))}));function m(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,a=new Array(o);a[0]=p;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s.mdxType="string"==typeof e?e:r,a[1]=s;for(var d=2;d<o;d++)a[d]=t[d];return i.createElement.apply(null,a)}return i.createElement.apply(null,t)}p.displayName="MDXCreateElement"},4697:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return s},contentTitle:function(){return c},metadata:function(){return d},toc:function(){return l},default:function(){return p}});var i=t(3117),r=t(102),o=(t(7294),t(3905)),a=["components"],s={title:"include/sleepy_discord/voice_connection.h"},c=void 0,d={unversionedId:"reference/Files/voice__connection_8h",id:"reference/Files/voice__connection_8h",title:"include/sleepy_discord/voice_connection.h",description:"Namespaces",source:"@site/docs/reference/Files/voice__connection_8h.md",sourceDirName:"reference/Files",slug:"/reference/Files/voice__connection_8h",permalink:"/sleepy-discord/docs/reference/Files/voice__connection_8h",tags:[],version:"current",frontMatter:{title:"include/sleepy_discord/voice_connection.h"},sidebar:"Reference",previous:{title:"sleepy_discord/voice_connection.cpp",permalink:"/sleepy-discord/docs/reference/Files/voice__connection_8cpp"},next:{title:"sleepy_discord/webhook.cpp",permalink:"/sleepy-discord/docs/reference/Files/webhook_8cpp"}},l=[{value:"Namespaces",id:"namespaces",children:[],level:2},{value:"Classes",id:"classes",children:[],level:2},{value:"Types",id:"types",children:[],level:2},{value:"Types Documentation",id:"types-documentation",children:[{value:"enum AudioSourceType",id:"enum-audiosourcetype",children:[],level:3},{value:"using AudioSample",id:"using-audiosample",children:[],level:3},{value:"using AudioPointerSource",id:"using-audiopointersource",children:[],level:3}],level:2},{value:"Source code",id:"source-code",children:[],level:2}],u={toc:l};function p(e){var n=e.components,t=(0,r.Z)(e,a);return(0,o.kt)("wrapper",(0,i.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"namespaces"},"Namespaces"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Name"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Namespaces/namespace_sleepy_discord"},"SleepyDiscord")))))),(0,o.kt)("h2",{id:"classes"},"Classes"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null}),(0,o.kt)("th",{parentName:"tr",align:null},"Name"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"class"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/class_sleepy_discord_1_1_base_voice_event_handler"},"SleepyDiscord::BaseVoiceEventHandler")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_voice_context"},"SleepyDiscord::VoiceContext")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_audio_transmission_details"},"SleepyDiscord::AudioTransmissionDetails")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_base_audio_source"},"SleepyDiscord::BaseAudioSource")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_base_audio_output"},"SleepyDiscord::BaseAudioOutput")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_audio_timer"},"SleepyDiscord::AudioTimer")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"class"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/class_sleepy_discord_1_1_voice_connection"},"SleepyDiscord::VoiceConnection")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_basic_audio_source_for_containers"},"SleepyDiscord::BasicAudioSourceForContainers")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_audio_source"},"SleepyDiscord::AudioSource")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"struct"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Classes/struct_sleepy_discord_1_1_audio_vector_source"},"SleepyDiscord::AudioVectorSource")))))),(0,o.kt)("h2",{id:"types"},"Types"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null}),(0,o.kt)("th",{parentName:"tr",align:null},"Name"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"enum"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Files/voice__connection_8h#enum-audiosourcetype"},"AudioSourceType"))," { AUDIO_BASE_TYPE, AUDIO_CONTAINER}")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"using int16_t"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Files/voice__connection_8h#using-audiosample"},"AudioSample")))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"using BaseAudioSource"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"/sleepy-discord/docs/reference/Files/voice__connection_8h#using-audiopointersource"},"AudioPointerSource")))))),(0,o.kt)("h2",{id:"types-documentation"},"Types Documentation"),(0,o.kt)("h3",{id:"enum-audiosourcetype"},"enum AudioSourceType"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Enumerator"),(0,o.kt)("th",{parentName:"tr",align:null},"Value"),(0,o.kt)("th",{parentName:"tr",align:null},"Description"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"AUDIO_BASE_TYPE"),(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"AUDIO_CONTAINER"),(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null})))),(0,o.kt)("h3",{id:"using-audiosample"},"using AudioSample"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cpp"},"using SleepyDiscord::AudioSample = typedef int16_t;\n")),(0,o.kt)("h3",{id:"using-audiopointersource"},"using AudioPointerSource"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cpp"},"using SleepyDiscord::AudioPointerSource = typedef BaseAudioSource;\n")),(0,o.kt)("h2",{id:"source-code"},"Source code"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cpp"},'#pragma once\n#include <vector>\n#include <array>\n#include <cstdint>\n#include <list>\n#if (!defined(NONEXISTENT_OPUS) && !defined(SLEEPY_DISCORD_CMAKE)) || defined(EXISTENT_OPUS)\n#include <opus.h>\n#endif\n#include "udp_client.h"\n#include "snowflake.h"\n#include "server.h"\n#include "channel.h"\n#include "message_receiver.h"\n#include "timer.h"\n\nnamespace SleepyDiscord {\n    using AudioSample = int16_t;\n\n    class BaseDiscordClient;\n    class VoiceConnection;\n\n    class BaseVoiceEventHandler {\n    public:\n        virtual ~BaseVoiceEventHandler() = default;\n        virtual void onReady(VoiceConnection&) {}\n        virtual void onSpeaking(VoiceConnection&) {}\n        virtual void onEndSpeaking(VoiceConnection&) {}\n        virtual void onFinishedSpeaking(VoiceConnection&) {}\n        virtual void onHeartbeat(VoiceConnection&) {}\n        virtual void onHeartbeatAck(VoiceConnection&) {}\n    };\n\n    struct VoiceContext {\n        friend VoiceConnection;\n        friend BaseDiscordClient;\n    public:\n        inline Snowflake<Channel> getChannelID() {\n            return channelID;\n        }\n\n        inline Snowflake<Server> getServerID() {\n            return serverID;\n        }\n\n        inline bool operator==(const VoiceContext& right) {\n            return this == &right;\n        }\n\n        inline void setVoiceHandler(BaseVoiceEventHandler* source) {\n            eventHandler = std::unique_ptr<BaseVoiceEventHandler>(source);\n        }\n\n        inline bool hasVoiceHandler() {\n            return eventHandler != nullptr;\n        }\n\n        inline BaseVoiceEventHandler& getVoiceHandler() {\n            return *(eventHandler.get());\n        }\n\n        template<class EventHandler, class... Types>\n        inline void startVoiceHandler(Types&&... arguments) {\n            setVoiceHandler(new EventHandler(std::forward<Types>(arguments)...));\n        }\n\n    private:\n        VoiceContext(Snowflake<Server> _serverID, Snowflake<Channel> _channelID, BaseVoiceEventHandler* _eventHandler) :\n            serverID(_serverID), channelID(_channelID), eventHandler(_eventHandler)\n        {}\n\n        Snowflake<Server> serverID;\n        Snowflake<Channel> channelID;\n        std::string sessionID = "";\n        std::string endpoint = "";\n        std::string token;\n        std::unique_ptr<BaseVoiceEventHandler> eventHandler;\n    };\n\n    enum AudioSourceType {\n        AUDIO_BASE_TYPE,\n        AUDIO_CONTAINER,\n    };\n\n    class VoiceConnection;\n\n    struct AudioTransmissionDetails {\n    public:\n        inline VoiceContext& context() {\n            return _context;\n        }\n\n        inline std::size_t amountSentSinceLastTime() {\n            return _amountSentSinceLastTime;\n        }\n\n        static inline constexpr int bitrate() {\n            return 48000;\n        }\n\n        static inline constexpr int channels() {\n            return 2;\n        }\n\n        static inline constexpr std::size_t proposedLengthOfTime() {\n            return 20;\n        }\n\n        static inline constexpr std::size_t proposedLength() {\n            return static_cast<std::size_t>(\n                bitrate() * channels() * (\n                    static_cast<float>(proposedLengthOfTime()) / 1000 /*millisecond conversion*/\n                )\n            );\n        }\n\n    private:\n        friend VoiceConnection;\n        AudioTransmissionDetails(\n            VoiceContext& con,\n            const std::size_t amo\n        ) :\n            _context(con),\n            _amountSentSinceLastTime(amo)\n        { }\n\n        VoiceContext& _context;\n        const std::size_t _amountSentSinceLastTime;\n    };\n\n    struct BaseAudioSource {\n        BaseAudioSource() : type(AUDIO_BASE_TYPE) {}\n        explicit BaseAudioSource(AudioSourceType typ) : type(typ) {}\n        virtual inline bool isOpusEncoded() { return false; }\n        const AudioSourceType type;\n        virtual ~BaseAudioSource() = default;\n        //This function below is here in case the user uses this class\n        virtual void read(AudioTransmissionDetails& /*details*/, int16_t*& /*buffer*/, std::size_t& /*length*/) {};\n\n        enum SpeakingFlag : unsigned int {\n            Microphone = 1u << 0u,\n            Soundshare = 1u << 1u,\n            Priority = 1u << 2u,\n        };\n        SpeakingFlag speakingFlag = Microphone;\n    };\n\n    struct BaseAudioOutput {\n        using Container = std::array<AudioSample, AudioTransmissionDetails::proposedLength()>;\n        BaseAudioOutput() = default;\n        virtual ~BaseAudioOutput() = default;\n        virtual void write(Container audio, AudioTransmissionDetails& details) {}\n    private:\n        friend VoiceConnection;\n    };\n\n    struct AudioTimer {\n        Timer timer;\n        time_t nextTime = 0;\n        void stop() {\n            if (timer.isValid())\n                timer.stop();\n        }\n    };\n\n    class VoiceConnection : public GenericMessageReceiver {\n    public:\n        VoiceConnection(BaseDiscordClient* client, VoiceContext& _context);\n        VoiceConnection(VoiceConnection&&) = default;\n\n        ~VoiceConnection() = default;\n\n        inline bool operator==(const VoiceConnection& right) {\n            return this == &right;\n        }\n\n        inline bool isReady() const {\n            return state & State::ABLE;\n        }\n\n        inline void setAudioSource(BaseAudioSource*& source) {\n            audioSource = std::unique_ptr<BaseAudioSource>(source);\n        }\n\n        inline bool hasAudioSource() const {\n            return audioSource != nullptr;\n        }\n\n        inline BaseAudioSource& getAudioSource() {\n            return *audioSource;\n        }\n\n        /*To do there might be a way to prevent code reuse here*/\n\n        inline void setAudioOutput(BaseAudioOutput*& output) {\n            audioOutput = std::unique_ptr<BaseAudioOutput>(output);\n        } \n\n        inline bool hasAudioOutput() const {\n            return audioOutput != nullptr;\n        }\n\n        inline BaseAudioOutput& getAudioOutput() {\n            return *audioOutput;\n        }\n\n        //=== startSpeaking functions ===\n\n        void startSpeaking();\n\n        inline void startSpeaking(BaseAudioSource* source) {\n            setAudioSource(source);\n            startSpeaking();\n        }\n\n        template<class AudioSource, class... Types>\n        inline void startSpeaking(Types&&... arguments) {\n            startSpeaking(new AudioSource(std::forward<Types>(arguments)...));\n        }\n\n        //=== startListening ===\n\n        void startListening();\n\n        inline BaseDiscordClient& getDiscordClient() {\n            return *origin;\n        }\n\n        inline BaseDiscordClient& getOrigin() {\n            return getDiscordClient();\n        }\n\n        inline VoiceContext& getContext() {\n            return context;\n        }\n\n        void speak(AudioSample*& audioData, const std::size_t& length);\n\n        void disconnect();\n\n        //Discord doens\'t gives the endpoint with wss:// or ?v=3, so it\'s done here\n        static std::string getWebSocketURI(const std::string& givenEndpoint) {\n            std::string endpoint;\n            //length of wss:///?v=3 is 11, plus one equals 12\n            endpoint.reserve(12 + givenEndpoint.length());\n            endpoint += "wss://";\n            endpoint += givenEndpoint;\n            endpoint += "/?v=3";\n            return endpoint;\n        }\n    private:\n        friend BaseDiscordClient;\n\n        void initialize() override;\n        void processMessage(const std::string &message) override;\n        void processCloseCode(const int16_t code) override;\n\n        enum VoiceOPCode {\n            IDENTIFY            = 0,  //client begin a voice websocket connection\n            SELECT_PROTOCOL     = 1,  //client select the voice protocol\n            READY               = 2,  //server complete the websocket handshake\n            HEARTBEAT           = 3,  //client keep the websocket connection alive\n            SESSION_DESCRIPTION = 4,  //server describe the session\n            SPEAKING            = 5,  //both   indicate which users are speaking\n            HEARTBEAT_ACK       = 6,  //server sent immediately following a received client heartbeat\n            RESUME              = 7,  //client resume a connection\n            HELLO               = 8,  //server the continuous interval in milliseconds after which the client should send a heartbeat\n            RESUMED             = 9,  //server acknowledge Resume\n            CLIENT_DISCONNECT   = 13  //server a client has disconnected from the voice channel\n        };\n            \n        enum State : uint8_t {\n            NOT_CONNECTED = 0 << 0,\n            CONNECTED     = 1 << 0,\n            OPEN          = 1 << 1,\n            AUDIO_ENABLED = 1 << 2,\n            SENDING_AUDIO = 1 << 3,\n\n            CAN_ENCODE    = 1 << 6,\n            CAN_DECODE    = 1 << 7,\n\n            ABLE          = CONNECTED | OPEN | AUDIO_ENABLED,\n        };\n\n#ifdef NONEXISTENT_OPUS\n        using OpusEncoder = void;\n        using OpusDecoder = void;\n#endif\n\n        BaseDiscordClient* origin;\n        VoiceContext& context;\n        UDPClient UDP;\n        time_t heartbeatInterval = 0;\n        uint32_t sSRC;\n        uint16_t port;\n        Timer heart;\n        State state = State::NOT_CONNECTED;\n        int16_t numOfPacketsSent = 0;\n        std::unique_ptr<BaseAudioSource> audioSource;\n        std::unique_ptr<BaseAudioOutput> audioOutput;\n        AudioTimer speechTimer;\n        AudioTimer listenTimer;\n        std::size_t samplesSentLastTime = 0;\n        time_t nextTime = 0;\n        OpusEncoder *encoder = nullptr;\n        OpusDecoder *decoder = nullptr;\n        uint16_t sequence = 0;\n        uint32_t timestamp = 0;\n\n        std::array<unsigned char, 32> secretKey;\n        static constexpr int nonceSize = 24;\n\n        //to do use this for events\n        template<class... Types>\n        inline void callEvent(void (BaseVoiceEventHandler::*member)(Types...), Types&&... arguments){\n            if(context.eventHandler != nullptr)\n                ((*context.eventHandler).*member)(arguments...);\n        }\n        void heartbeat();\n        inline void scheduleNextTime(AudioTimer& timer, TimedTask code, const time_t interval);\n        inline void stopSpeaking() {\n            state = static_cast<State>(state & ~SENDING_AUDIO);\n        }\n        void sendSpeaking(bool isNowSpeaking);\n        void speak();\n        void sendAudioData(\n            uint8_t*& encodedAudioData,\n            const std::size_t & length,\n            const std::size_t & frameSize\n        );\n        void listen();\n        void processIncomingAudio(const std::vector<uint8_t>& data);\n    };\n\n    struct BasicAudioSourceForContainers : public BaseAudioSource {\n        BasicAudioSourceForContainers() : BaseAudioSource(AUDIO_CONTAINER) {}\n        virtual void speak(\n            VoiceConnection& connection,\n            AudioTransmissionDetails& details,\n            std::size_t& length\n        ) = 0;\n    };\n\n    template<class _Container>\n    struct AudioSource : public BasicAudioSourceForContainers {\n    public:\n        using Container = _Container;\n        AudioSource() : BasicAudioSourceForContainers() {}\n        virtual void read(AudioTransmissionDetails& /*details*/, int16_t*& /*buffer*/, std::size_t& /*length*/)  override {};\n        virtual void read(AudioTransmissionDetails& details, Container& target) {};\n    private:\n        friend VoiceConnection;\n        void speak(\n            VoiceConnection& connection,\n            AudioTransmissionDetails& details,\n            std::size_t& length\n        ) override {\n            read(details, containedAudioData);\n            int16_t* audioBuffer = containedAudioData.data();\n            length = containedAudioData.size();\n            connection.speak(audioBuffer, length);\n        }\n    protected:\n        Container containedAudioData;\n    };\n\n    struct AudioVectorSource : public AudioSource<std::vector<AudioSample>> {\n    public:\n        AudioVectorSource() : AudioSource<std::vector<AudioSample>>() {\n            containedAudioData.resize(AudioTransmissionDetails::proposedLength());\n        }\n    };\n\n    using AudioPointerSource = BaseAudioSource;\n}\n')),(0,o.kt)("hr",null),(0,o.kt)("p",null,"Updated on 28 October 2023 at 21:20:08 UTC"))}p.isMDXComponent=!0}}]);